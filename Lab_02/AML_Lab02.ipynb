{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JP9Qqn5fq2Y"
      },
      "source": [
        "# Lab 02: Training a Custom Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA2wrFjFna7x"
      },
      "source": [
        "**Objective of this lab**: training a small custom model on the Tiny-ImageNet dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using MPS (Metal Performance Shaders) - Apple GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Usa MPS per Mac (Apple Silicon) o CPU come fallback\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"✓ Using MPS (Metal Performance Shaders) - Apple GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"✓ Using CUDA - NVIDIA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"✓ Using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF_SzW86f8kM"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecXsQI0_f6pv",
        "outputId": "b60872fd-6420-4feb-fcaa-4761fa276cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already downloaded.\n",
            "Dataset already extracted.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Percorso della cartella data nella directory padre\n",
        "data_dir = '../data'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Download del dataset\n",
        "url = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
        "zip_path = os.path.join(data_dir, 'tiny-imagenet-200.zip')\n",
        "extract_dir = os.path.join(data_dir, 'tiny-imagenet')\n",
        "\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Downloading Tiny ImageNet dataset...\")\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "    print(\"Download completed!\")\n",
        "else:\n",
        "    print(\"Dataset already downloaded.\")\n",
        "\n",
        "# Estrazione del file zip\n",
        "if not os.path.exists(os.path.join(extract_dir, 'tiny-imagenet-200')):\n",
        "    print(\"Extracting dataset...\")\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(\"Extraction completed!\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vei0UbVTkkPN"
      },
      "source": [
        "We need to adjust the format of the val split of the dataset to be used with ImageFolder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HuUvU_Gug7Gk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation dataset already reorganized.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "val_images_dir = '../data/tiny-imagenet/tiny-imagenet-200/val/images'\n",
        "\n",
        "# Controlla se la riorganizzazione è già stata fatta\n",
        "if os.path.exists(val_images_dir):\n",
        "    print(\"Reorganizing validation dataset...\")\n",
        "    with open('../data/tiny-imagenet/tiny-imagenet-200/val/val_annotations.txt') as f:\n",
        "        for line in f:\n",
        "            fn, cls, *_ = line.split('\\t')\n",
        "            os.makedirs(f'../data/tiny-imagenet/tiny-imagenet-200/val/{cls}', exist_ok=True)\n",
        "            shutil.copyfile(f'{val_images_dir}/{fn}', \n",
        "                            f'../data/tiny-imagenet/tiny-imagenet-200/val/{cls}/{fn}')\n",
        "    \n",
        "    shutil.rmtree(val_images_dir)\n",
        "    print(\"Validation dataset reorganized successfully!\")\n",
        "else:\n",
        "    print(\"Validation dataset already reorganized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xt1X5euKfoEd"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),  # Resize to fit the input dimensions of the network\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# root/{classX}/x001.jpg\n",
        "\n",
        "tiny_imagenet_dataset_train = ImageFolder(root='../data/tiny-imagenet/tiny-imagenet-200/train', transform=transform)\n",
        "tiny_imagenet_dataset_val = ImageFolder(root='../data/tiny-imagenet/tiny-imagenet-200/val', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtIrYRaxg6pw",
        "outputId": "0a1fe15b-df27-444d-a094-4917c25e0258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of train dataset: 100000\n",
            "Length of val dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of train dataset: {len(tiny_imagenet_dataset_train)}\")\n",
        "print(f\"Length of val dataset: {len(tiny_imagenet_dataset_val)}\")\n",
        "\n",
        "# The following code also checks the number of samples per class\n",
        "# from collections import Counter\n",
        "\n",
        "# class_counts = Counter([target for _, target in tiny_imagenet_dataset_val])\n",
        "# for class_label, count in class_counts.items():\n",
        "#     print(f\"Class {class_label}: {count} entries\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExF2yRw9mT8G",
        "outputId": "0df6e3ad-81d1-46a1-9772-6b885bc3137b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(tiny_imagenet_dataset_train, batch_size=32, shuffle=True, num_workers=8)\n",
        "val_loader = torch.utils.data.DataLoader(tiny_imagenet_dataset_val, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0AIe8afloCR"
      },
      "source": [
        "## Custom model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vpdGGfa8lDde"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "num_classes = 200 # 200 is the number of classes in TinyImageNet\n",
        "\n",
        "# Define the custom neural network\n",
        "class CustomNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomNet, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        Due 3x3 ti danno un campo recettivo di 5x5 con meno parametri e più flessibilità grazie alle attivazioni non-lineari intermedie!\n",
        "\n",
        "        Prima Conv (3x3):\n",
        "        Input: [A B C D E F G]    Kernel copre: [B C D]\n",
        "                                  Output: X (dipende da B,C,D)\n",
        "\n",
        "        Seconda Conv (3x3):\n",
        "        Input dal primo layer: [... X Y Z ...]    Kernel copre: [X Y Z]\n",
        "                                                  Output finale: W\n",
        "\n",
        "        W dipende da X,Y,Z\n",
        "        Ma X dipende da A,B,C,D\n",
        "        Y dipende da B,C,D,E\n",
        "        Z dipende da C,D,E,F\n",
        "\n",
        "        Quindi W dipende da: A,B,C,D,E,F = 5 pixel di larghezza!\n",
        "        \"\"\"\n",
        "\n",
        "        # Convolutional blocks\n",
        "        # Block 1\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # 64x64 -> 32x32\n",
        "\n",
        "        # Block 2\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 112x112 -> 56x56\n",
        "\n",
        "        # Block 3\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "        self.conv7 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn7 = nn.BatchNorm2d(256)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)  # 56x56 -> 28x28\n",
        "\n",
        "        # Block 4\n",
        "        self.conv8 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn8 = nn.BatchNorm2d(512)\n",
        "        self.conv9 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn9 = nn.BatchNorm2d(512)\n",
        "        self.conv10 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn10 = nn.BatchNorm2d(512)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
        "\n",
        "        # Block 5\n",
        "        self.conv11 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn11 = nn.BatchNorm2d(512)\n",
        "        self.conv12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn12 = nn.BatchNorm2d(512)\n",
        "        self.conv13 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn13 = nn.BatchNorm2d(512)\n",
        "        self.pool5 = nn.MaxPool2d(2, 2)  # 14x14 -> 7x7\n",
        "\n",
        "        # Global Average Pooling (più moderno del flatten)\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(512, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes) # professore si ferma a 256 noi andiamo ancora di un livello in più\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input: B x 3 x 224 x 224\n",
        "\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Block 3\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = F.relu(self.bn6(self.conv6(x)))\n",
        "        x = F.relu(self.bn7(self.conv7(x)))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Block 4\n",
        "        x = F.relu(self.bn8(self.conv8(x)))\n",
        "        x = F.relu(self.bn9(self.conv9(x)))\n",
        "        x = F.relu(self.bn10(self.conv10(x)))\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        # Block 5\n",
        "        x = F.relu(self.bn11(self.conv11(x)))\n",
        "        x = F.relu(self.bn12(self.conv12(x)))\n",
        "        x = F.relu(self.bn13(self.conv13(x)))\n",
        "        x = self.pool5(x)\n",
        "\n",
        "        # Global Average Pooling e FC\n",
        "        x = self.global_avg_pool(x)   # B x 512 x 1 x 1\n",
        "        x = x.view(x.size(0), -1)     # B x 512\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zM0eatFllREw"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Azzera i gradienti dall'iterazione precedente\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calcola la loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward pass (calcola i gradienti)\n",
        "        loss.backward()\n",
        "\n",
        "        # Aggiorna i pesi\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "    print(f'Train Epoch: {epoch} Loss: {train_loss:.6f} Acc: {train_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LUicYRJamITD"
      },
      "outputs": [],
      "source": [
        "# Validation loop\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass (solo inference, no training)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calcola la loss\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'Validation Loss: {val_loss:.6f} Acc: {val_accuracy:.2f}%')\n",
        "    return val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhr8xxEUmmGD"
      },
      "source": [
        "## Putting everything together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lO-VJtZml6t",
        "outputId": "f5f53623-da74-4b33-f900-bb9fa5618065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Starting training for 10 epochs\n",
            "Device: mps\n",
            "Training samples: 100000\n",
            "Validation samples: 10000\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "EPOCH 1/10\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "model = CustomNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "best_acc = 0\n",
        "num_epochs = 10\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Starting training for {num_epochs} epochs\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Training samples: {len(tiny_imagenet_dataset_train)}\")\n",
        "print(f\"Validation samples: {len(tiny_imagenet_dataset_val)}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EPOCH {epoch}/{num_epochs}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Training phase\n",
        "    train(epoch, model, train_loader, criterion, optimizer, device)\n",
        "    \n",
        "    # Validation phase\n",
        "    val_accuracy = validate(model, val_loader, criterion, device)\n",
        "    \n",
        "    # Track best accuracy\n",
        "    if val_accuracy > best_acc:\n",
        "        best_acc = val_accuracy\n",
        "        print(f\"✓ New best validation accuracy: {best_acc:.2f}%\")\n",
        "    \n",
        "    # Epoch timing\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    print(f\"Epoch {epoch} completed in {epoch_time:.2f}s\")\n",
        "    print(f\"Current best accuracy: {best_acc:.2f}%\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"TRAINING COMPLETED\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f'Best validation accuracy achieved: {best_acc:.2f}%')\n",
        "print(f\"{'='*60}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lab-02-FwKjGVD7-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
