{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab372ea",
   "metadata": {},
   "source": [
    "# VGG16 Fine-tuning - Cats vs Dogs\n",
    "## Google Colab Training Notebook\n",
    "\n",
    "Questo notebook implementa il fine-tuning di VGG16 seguendo lo stile del Lab3 con integrazione Wandb.\n",
    "\n",
    "**Assicurati di:**\n",
    "- ✅ Abilitare GPU: Runtime → Change runtime type → GPU\n",
    "- ✅ Avere un account Wandb: [wandb.ai](https://wandb.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30adb270",
   "metadata": {},
   "source": [
    "## 1️⃣ Setup - Clone Repository e Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/ghMellow/polito-aml-project_skeleton.git\n",
    "%cd polito-aml-project_skeleton\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q torch torchvision numpy pandas Pillow torchsummary wandb kagglehub matplotlib\n",
    "\n",
    "print(\"\\n✅ Setup completato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed22fe",
   "metadata": {},
   "source": [
    "## 2️⃣ Wandb Authentication\n",
    "\n",
    "Ottieni la tua API key da: https://wandb.ai/authorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86dbb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Inserisci la tua API key da: https://wandb.ai/authorize\n",
    "wandb.login(key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "print(\"✅ Wandb autenticato!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e8e83",
   "metadata": {},
   "source": [
    "## 3️⃣ Download Dataset Cats vs Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Download dataset\n",
    "print(\"Downloading dataset... (potrebbe richiedere alcuni minuti)\")\n",
    "path = kagglehub.dataset_download(\"tongpython/cat-and-dog\")\n",
    "print(f\"✓ Dataset scaricato in: {path}\")\n",
    "\n",
    "# Move to data folder\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "for item in os.listdir(path):\n",
    "    src = os.path.join(path, item)\n",
    "    dst = os.path.join('./data', item)\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.move(src, dst)\n",
    "        print(f\"  - Moved {item}\")\n",
    "\n",
    "print(\"\\n✅ Dataset pronto!\")\n",
    "print(\"Struttura:\")\n",
    "!ls -la ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce25d1f",
   "metadata": {},
   "source": [
    "## 4️⃣ Metodo 1: Training con CLI (Veloce)\n",
    "\n",
    "Usa direttamente lo script `train.py` con Wandb integrato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training con script CLI\n",
    "!python train.py \\\n",
    "    --data_dir ./data \\\n",
    "    --epochs 10 \\\n",
    "    --batch_size 128 \\\n",
    "    --lr 0.0001 \\\n",
    "    --use_wandb \\\n",
    "    --wandb_project \"vgg16-cats-vs-dogs-colab\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f9073",
   "metadata": {},
   "source": [
    "### Evaluation (Metodo CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234542a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval.py \\\n",
    "    --checkpoint ./checkpoints/best_model.pth \\\n",
    "    --data_dir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ca2ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5️⃣ Metodo 2: Training Programmatico (Stile Slide Professore)\n",
    "\n",
    "Controllo completo del training loop seguendo lo stile dello slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a1260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import wandb\n",
    "\n",
    "# Custom modules\n",
    "from dataset import CustomImageDataset, create_annotations_csv\n",
    "from models import create_vgg16_model, count_trainable_parameters\n",
    "from utils import get_train_transforms, get_val_test_transforms, plot_training_history\n",
    "\n",
    "print(\"✅ Imports completati!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start a W&B run (SLIDE PROFESSORE)\n",
    "wandb.init(\n",
    "    project='vgg16-cats-vs-dogs',\n",
    "    name='feature-extraction-colab',\n",
    "    tags=['vgg16', 'transfer-learning', 'cats-vs-dogs', 'colab']\n",
    ")\n",
    "\n",
    "# 2. Save model inputs and hyperparameters (SLIDE PROFESSORE)\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.0001\n",
    "config.batch_size = 128\n",
    "config.epochs = 10\n",
    "config.momentum = 0.9\n",
    "config.val_split = 0.2\n",
    "config.architecture = 'VGG16'\n",
    "config.mode = 'feature_extraction'\n",
    "config.num_classes = 2\n",
    "\n",
    "print(\"✅ Wandb inizializzato\")\n",
    "print(f\"  - Project: {wandb.run.project}\")\n",
    "print(f\"  - Run: {wandb.run.name}\")\n",
    "print(f\"  - URL: {wandb.run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85525d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✓ Device: {device}\")\n",
    "\n",
    "# Dataset paths\n",
    "data_dir = './data'\n",
    "train_path = os.path.join(data_dir, 'training_set/training_set')\n",
    "test_path = os.path.join(data_dir, 'test_set/test_set')\n",
    "\n",
    "# Create annotations\n",
    "if not os.path.exists('train_annotations.csv'):\n",
    "    print(\"Creando annotations...\")\n",
    "    create_annotations_csv(train_path, 'train_annotations.csv')\n",
    "    create_annotations_csv(test_path, 'test_annotations.csv')\n",
    "\n",
    "# Transforms\n",
    "train_transform = get_train_transforms()\n",
    "val_transform = get_val_test_transforms()\n",
    "\n",
    "# Datasets\n",
    "train_dataset = CustomImageDataset('train_annotations.csv', train_path, transform=train_transform)\n",
    "valid_dataset = CustomImageDataset('train_annotations.csv', train_path, transform=val_transform)\n",
    "\n",
    "# Split\n",
    "indices = list(range(len(train_dataset)))\n",
    "split = int(np.floor(config.val_split * len(train_dataset)))\n",
    "train_sample = SubsetRandomSampler(indices[split:])\n",
    "valid_sample = SubsetRandomSampler(indices[:split])\n",
    "\n",
    "# Dataloaders\n",
    "trainloader = DataLoader(train_dataset, sampler=train_sample, batch_size=config.batch_size)\n",
    "validloader = DataLoader(valid_dataset, sampler=valid_sample, batch_size=config.batch_size)\n",
    "\n",
    "print(f\"✅ Dataset pronto\")\n",
    "print(f\"  - Training samples: {len(indices[split:])}\")\n",
    "print(f\"  - Validation samples: {len(indices[:split])}\")\n",
    "print(f\"  - Batch size: {config.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2862fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_vgg16_model(num_classes=2, pretrained=True, freeze_base=True)\n",
    "model = model.to(device)\n",
    "\n",
    "trainable, total = count_trainable_parameters(model)\n",
    "print(f\"✅ Model creato\")\n",
    "print(f\"  - Trainable: {trainable:,} / {total:,}\")\n",
    "print(f\"  - Mode: Feature Extraction\")\n",
    "\n",
    "# Watch model with wandb\n",
    "wandb.watch(model, log='all', log_freq=100)\n",
    "print(\"  - Wandb watching gradients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36256e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "parameters_to_optimize = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.SGD(parameters_to_optimize, lr=config.learning_rate, momentum=config.momentum)\n",
    "\n",
    "print(\"✅ Training setup\")\n",
    "print(f\"  - Loss: CrossEntropyLoss\")\n",
    "print(f\"  - Optimizer: SGD (lr={config.learning_rate}, momentum={config.momentum})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e621aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    # === TRAINING ===\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_loss = running_loss / len(trainloader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # === VALIDATION ===\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in validloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    valid_loss = running_loss / len(validloader)\n",
    "    valid_acc = correct / total\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracies.append(valid_acc)\n",
    "    \n",
    "    # 3. Log metrics over time to visualize performance (SLIDE PROFESSORE)\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"valid_accuracy\": valid_acc,\n",
    "        \"learning_rate\": config.learning_rate\n",
    "    })\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{config.epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Valid Loss: {valid_loss:.4f} | \"\n",
    "          f\"Valid Acc: {valid_acc:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if valid_loss < best_val_loss:\n",
    "        best_val_loss = valid_loss\n",
    "        os.makedirs('./checkpoints', exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'valid_loss': valid_loss,\n",
    "            'valid_accuracy': valid_acc,\n",
    "        }, './checkpoints/best_model.pth')\n",
    "        print(f\"  ✓ New best model saved!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Finish wandb\n",
    "wandb.finish()\n",
    "\n",
    "print(f\"\\n✅ Training completato!\")\n",
    "print(f\"Visualizza i risultati su: {wandb.run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(train_losses, valid_losses, title='Training History - Feature Extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = CustomImageDataset('test_annotations.csv', test_path, transform=val_transform)\n",
    "testloader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('./checkpoints/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Test\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "test_loss /= total\n",
    "test_accuracy = correct / total\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Average loss: {test_loss:.4f}\")\n",
    "print(f\"Accuracy: {correct}/{total} ({100. * test_accuracy:.2f}%)\")\n",
    "print(f\"Error rate: {100. * (1 - test_accuracy):.2f}%\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0143385",
   "metadata": {},
   "source": [
    "## 6️⃣ (Opzionale) Salva Checkpoint su Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9258bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy checkpoints to Drive\n",
    "!mkdir -p /content/drive/MyDrive/vgg16_checkpoints\n",
    "!cp -r ./checkpoints/* /content/drive/MyDrive/vgg16_checkpoints/\n",
    "\n",
    "print(\"✅ Checkpoints salvati su Google Drive!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
