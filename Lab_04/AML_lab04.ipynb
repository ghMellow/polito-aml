{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAUSSe_0-rac"
      },
      "source": [
        "### PyTorch AlexNet Exercises\n",
        "\n",
        "Welcome to the PyTorch AlexNet exercise template notebook.\n",
        "\n",
        "There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using MPS (Metal Performance Shaders) - Apple GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Usa MPS per Mac (Apple Silicon) o CPU come fallback\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"✓ Using MPS (Metal Performance Shaders) - Apple GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"✓ Using CUDA - NVIDIA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"✓ Using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estrai dataset da zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rvlgLzhBIBZ",
        "outputId": "8f3d7b13-41a4-42d9-a5c8-e428595c3c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting Tiny ImageNet dataset...\n",
            "Dataset extracted successfully!\n",
            "Reorganizing validation set...\n",
            "Validation set reorganized successfully!\n",
            "\n",
            "Dataset ready!\n",
            "Train classes: 200\n",
            "Validation classes: 200\n",
            "\n",
            "Train path: tiny-imagenet-200/train\n",
            "Validation path: tiny-imagenet-200/val\n",
            "\n",
            "Update your code paths to:\n",
            "  train_dataset = datasets.ImageFolder('tiny-imagenet-200/train', transform=transform)\n",
            "  val_dataset = datasets.ImageFolder('tiny-imagenet-200/val', transform=transform)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Percorso del file zip\n",
        "zip_path = '../data/tiny-imagenet-200.zip'\n",
        "extract_path = '../data/tiny-imagenet-200'\n",
        "\n",
        "print(\"Extracting Tiny ImageNet dataset...\")\n",
        "# Estrai il dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('../data')\n",
        "\n",
        "print(\"Dataset extracted successfully!\")\n",
        "\n",
        "# Tiny ImageNet ha una struttura particolare per il validation set\n",
        "# Dobbiamo riorganizzarlo per renderlo compatibile con ImageFolder\n",
        "\n",
        "val_dir = os.path.join(extract_path, 'val')\n",
        "val_images_dir = os.path.join(val_dir, 'images')\n",
        "val_annotations_file = os.path.join(val_dir, 'val_annotations.txt')\n",
        "\n",
        "# Leggi le annotazioni del validation set\n",
        "print(\"Reorganizing validation set...\")\n",
        "val_img_dict = {}\n",
        "with open(val_annotations_file, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split('\\t')\n",
        "        img_name = parts[0]\n",
        "        class_id = parts[1]\n",
        "        val_img_dict[img_name] = class_id\n",
        "\n",
        "# Crea le directory per ogni classe nel validation set\n",
        "for class_id in set(val_img_dict.values()):\n",
        "    class_dir = os.path.join(val_dir, class_id)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "# Sposta le immagini nelle rispettive cartelle di classe\n",
        "for img_name, class_id in val_img_dict.items():\n",
        "    src = os.path.join(val_images_dir, img_name)\n",
        "    dst = os.path.join(val_dir, class_id, img_name)\n",
        "    if os.path.exists(src):\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Rimuovi la cartella images vuota\n",
        "if os.path.exists(val_images_dir):\n",
        "    os.rmdir(val_images_dir)\n",
        "\n",
        "# Rimuovi il file di annotazioni\n",
        "if os.path.exists(val_annotations_file):\n",
        "    os.remove(val_annotations_file)\n",
        "\n",
        "print(\"Validation set reorganized successfully!\")\n",
        "\n",
        "# Verifica la struttura\n",
        "train_path = os.path.join(extract_path, 'train')\n",
        "val_path = os.path.join(extract_path, 'val')\n",
        "\n",
        "num_train_classes = len([d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))])\n",
        "num_val_classes = len([d for d in os.listdir(val_path) if os.path.isdir(os.path.join(val_path, d))])\n",
        "\n",
        "print(f\"\\nDataset ready!\")\n",
        "print(f\"Train classes: {num_train_classes}\")\n",
        "print(f\"Validation classes: {num_val_classes}\")\n",
        "print(f\"\\nTrain path: {train_path}\")\n",
        "print(f\"Validation path: {val_path}\")\n",
        "print(\"\\nUpdate your code paths to:\")\n",
        "print(f\"  train_dataset = datasets.ImageFolder('{train_path}', transform=transform)\")\n",
        "print(f\"  val_dataset = datasets.ImageFolder('{val_path}', transform=transform)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y6Soee8EO4j"
      },
      "source": [
        "## AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FZUp9FpW-RqO",
        "outputId": "681f9590-7906-4e5e-c98b-51b5d500ca9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/nicolotermine/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms338680\u001b[0m (\u001b[33ms338680-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Experiment 1: LR=0.1, Batch Size=16, Weight Decay=0.0005\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml/Lab_04/wandb/run-20251118_214752-sjnydhyu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/s338680-politecnico-di-torino/alexnet-tiny-imagenet/runs/sjnydhyu' target=\"_blank\">lr0.1_bs16_wd0.0005</a></strong> to <a href='https://wandb.ai/s338680-politecnico-di-torino/alexnet-tiny-imagenet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/s338680-politecnico-di-torino/alexnet-tiny-imagenet' target=\"_blank\">https://wandb.ai/s338680-politecnico-di-torino/alexnet-tiny-imagenet</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/s338680-politecnico-di-torino/alexnet-tiny-imagenet/runs/sjnydhyu' target=\"_blank\">https://wandb.ai/s338680-politecnico-di-torino/alexnet-tiny-imagenet/runs/sjnydhyu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [1/10]\n",
            "  Batch [100/6250], Loss: 5.307, Acc: 0.56%\n",
            "  Batch [200/6250], Loss: 5.309, Acc: 0.41%\n",
            "  Batch [300/6250], Loss: 5.308, Acc: 0.44%\n",
            "  Batch [400/6250], Loss: 5.311, Acc: 0.41%\n",
            "  Batch [500/6250], Loss: 5.311, Acc: 0.47%\n",
            "  Batch [600/6250], Loss: 5.311, Acc: 0.53%\n",
            "  Batch [700/6250], Loss: 5.311, Acc: 0.51%\n",
            "  Batch [800/6250], Loss: 5.312, Acc: 0.51%\n",
            "  Batch [900/6250], Loss: 5.311, Acc: 0.50%\n",
            "  Batch [1000/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [1100/6250], Loss: 5.312, Acc: 0.54%\n",
            "  Batch [1200/6250], Loss: 5.312, Acc: 0.54%\n",
            "  Batch [1300/6250], Loss: 5.312, Acc: 0.50%\n",
            "  Batch [1400/6250], Loss: 5.312, Acc: 0.52%\n",
            "  Batch [1500/6250], Loss: 5.312, Acc: 0.52%\n",
            "  Batch [1600/6250], Loss: 5.312, Acc: 0.50%\n",
            "  Batch [1700/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [1800/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [1900/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [2000/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [2100/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [2200/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [2300/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [2400/6250], Loss: 5.312, Acc: 0.48%\n",
            "  Batch [2500/6250], Loss: 5.312, Acc: 0.48%\n",
            "  Batch [2600/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [2700/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [2800/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [2900/6250], Loss: 5.312, Acc: 0.48%\n",
            "  Batch [3000/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [3100/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [3200/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [3300/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [3400/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [3500/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [3600/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [3700/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [3800/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3900/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4000/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4100/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4200/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4300/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4400/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [4500/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4600/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4700/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4800/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4900/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [5000/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5100/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5200/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5300/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5400/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5500/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5600/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5700/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5800/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5900/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [6000/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [6100/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [6200/6250], Loss: 5.313, Acc: 0.50%\n",
            "Train Loss: 5.313, Train Acc: 0.50%\n",
            "Val Loss: 5.312, Val Acc: 0.50%\n",
            "\n",
            "Epoch [2/10]\n",
            "  Batch [100/6250], Loss: 5.315, Acc: 0.50%\n",
            "  Batch [200/6250], Loss: 5.315, Acc: 0.31%\n",
            "  Batch [300/6250], Loss: 5.316, Acc: 0.40%\n",
            "  Batch [400/6250], Loss: 5.314, Acc: 0.38%\n",
            "  Batch [500/6250], Loss: 5.313, Acc: 0.33%\n",
            "  Batch [600/6250], Loss: 5.312, Acc: 0.42%\n",
            "  Batch [700/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [800/6250], Loss: 5.313, Acc: 0.42%\n",
            "  Batch [900/6250], Loss: 5.313, Acc: 0.40%\n",
            "  Batch [1000/6250], Loss: 5.313, Acc: 0.41%\n",
            "  Batch [1100/6250], Loss: 5.313, Acc: 0.39%\n",
            "  Batch [1200/6250], Loss: 5.313, Acc: 0.42%\n",
            "  Batch [1300/6250], Loss: 5.313, Acc: 0.43%\n",
            "  Batch [1400/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [1500/6250], Loss: 5.313, Acc: 0.42%\n",
            "  Batch [1600/6250], Loss: 5.313, Acc: 0.41%\n",
            "  Batch [1700/6250], Loss: 5.313, Acc: 0.43%\n",
            "  Batch [1800/6250], Loss: 5.313, Acc: 0.43%\n",
            "  Batch [1900/6250], Loss: 5.313, Acc: 0.43%\n",
            "  Batch [2000/6250], Loss: 5.313, Acc: 0.43%\n",
            "  Batch [2100/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [2200/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [2300/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [2400/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [2500/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [2600/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [2700/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [2800/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [2900/6250], Loss: 5.313, Acc: 0.45%\n",
            "  Batch [3000/6250], Loss: 5.314, Acc: 0.45%\n",
            "  Batch [3100/6250], Loss: 5.313, Acc: 0.45%\n",
            "  Batch [3200/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [3300/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [3400/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [3500/6250], Loss: 5.313, Acc: 0.45%\n",
            "  Batch [3600/6250], Loss: 5.313, Acc: 0.44%\n",
            "  Batch [3700/6250], Loss: 5.313, Acc: 0.45%\n",
            "  Batch [3800/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [3900/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4000/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4100/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4200/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4300/6250], Loss: 5.314, Acc: 0.46%\n",
            "  Batch [4400/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4500/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4600/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4700/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4800/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4900/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [5000/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [5100/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [5200/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [5300/6250], Loss: 5.314, Acc: 0.46%\n",
            "  Batch [5400/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [5500/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [5600/6250], Loss: 5.314, Acc: 0.46%\n",
            "  Batch [5700/6250], Loss: 5.314, Acc: 0.46%\n",
            "  Batch [5800/6250], Loss: 5.314, Acc: 0.45%\n",
            "  Batch [5900/6250], Loss: 5.314, Acc: 0.45%\n",
            "  Batch [6000/6250], Loss: 5.314, Acc: 0.45%\n",
            "  Batch [6100/6250], Loss: 5.314, Acc: 0.45%\n",
            "  Batch [6200/6250], Loss: 5.314, Acc: 0.46%\n",
            "Train Loss: 5.314, Train Acc: 0.46%\n",
            "Val Loss: 5.312, Val Acc: 0.50%\n",
            "\n",
            "Epoch [3/10]\n",
            "  Batch [100/6250], Loss: 5.311, Acc: 0.62%\n",
            "  Batch [200/6250], Loss: 5.311, Acc: 0.75%\n",
            "  Batch [300/6250], Loss: 5.313, Acc: 0.67%\n",
            "  Batch [400/6250], Loss: 5.313, Acc: 0.64%\n",
            "  Batch [500/6250], Loss: 5.315, Acc: 0.60%\n",
            "  Batch [600/6250], Loss: 5.314, Acc: 0.58%\n",
            "  Batch [700/6250], Loss: 5.314, Acc: 0.54%\n",
            "  Batch [800/6250], Loss: 5.315, Acc: 0.52%\n",
            "  Batch [900/6250], Loss: 5.314, Acc: 0.50%\n",
            "  Batch [1000/6250], Loss: 5.314, Acc: 0.49%\n",
            "  Batch [1100/6250], Loss: 5.314, Acc: 0.49%\n",
            "  Batch [1200/6250], Loss: 5.314, Acc: 0.49%\n",
            "  Batch [1300/6250], Loss: 5.314, Acc: 0.51%\n",
            "  Batch [1400/6250], Loss: 5.314, Acc: 0.50%\n",
            "  Batch [1500/6250], Loss: 5.314, Acc: 0.52%\n",
            "  Batch [1600/6250], Loss: 5.314, Acc: 0.51%\n",
            "  Batch [1700/6250], Loss: 5.314, Acc: 0.49%\n",
            "  Batch [1800/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [1900/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [2000/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [2100/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [2200/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [2300/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [2400/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [2500/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [2600/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [2700/6250], Loss: 5.314, Acc: 0.51%\n",
            "  Batch [2800/6250], Loss: 5.314, Acc: 0.50%\n",
            "  Batch [2900/6250], Loss: 5.314, Acc: 0.50%\n",
            "  Batch [3000/6250], Loss: 5.314, Acc: 0.51%\n",
            "  Batch [3100/6250], Loss: 5.314, Acc: 0.51%\n",
            "  Batch [3200/6250], Loss: 5.314, Acc: 0.50%\n",
            "  Batch [3300/6250], Loss: 5.314, Acc: 0.49%\n",
            "  Batch [3400/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [3500/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [3600/6250], Loss: 5.314, Acc: 0.48%\n",
            "  Batch [3700/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3800/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3900/6250], Loss: 5.314, Acc: 0.48%\n",
            "  Batch [4000/6250], Loss: 5.314, Acc: 0.49%\n",
            "  Batch [4100/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4200/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [4300/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [4400/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [4500/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [4600/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [4700/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [4800/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [4900/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [5000/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [5100/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [5200/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [5300/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [5400/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [5500/6250], Loss: 5.313, Acc: 0.51%\n",
            "  Batch [5600/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [5700/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [5800/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [5900/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [6000/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [6100/6250], Loss: 5.313, Acc: 0.50%\n",
            "  Batch [6200/6250], Loss: 5.313, Acc: 0.50%\n",
            "Train Loss: 5.313, Train Acc: 0.50%\n",
            "Val Loss: 5.312, Val Acc: 0.50%\n",
            "\n",
            "Epoch [4/10]\n",
            "  Batch [100/6250], Loss: 5.311, Acc: 0.19%\n",
            "  Batch [200/6250], Loss: 5.312, Acc: 0.41%\n",
            "  Batch [300/6250], Loss: 5.311, Acc: 0.52%\n",
            "  Batch [400/6250], Loss: 5.311, Acc: 0.56%\n",
            "  Batch [500/6250], Loss: 5.312, Acc: 0.60%\n",
            "  Batch [600/6250], Loss: 5.311, Acc: 0.55%\n",
            "  Batch [700/6250], Loss: 5.312, Acc: 0.54%\n",
            "  Batch [800/6250], Loss: 5.311, Acc: 0.50%\n",
            "  Batch [900/6250], Loss: 5.312, Acc: 0.51%\n",
            "  Batch [1000/6250], Loss: 5.312, Acc: 0.49%\n",
            "  Batch [1100/6250], Loss: 5.312, Acc: 0.50%\n",
            "  Batch [1200/6250], Loss: 5.312, Acc: 0.50%\n",
            "  Batch [1300/6250], Loss: 5.312, Acc: 0.50%\n",
            "  Batch [1400/6250], Loss: 5.313, Acc: 0.52%\n",
            "  Batch [1500/6250], Loss: 5.312, Acc: 0.50%\n",
            "  Batch [1600/6250], Loss: 5.312, Acc: 0.48%\n",
            "  Batch [1700/6250], Loss: 5.312, Acc: 0.50%\n",
            "  Batch [1800/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [1900/6250], Loss: 5.312, Acc: 0.48%\n",
            "  Batch [2000/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [2100/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [2200/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [2300/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [2400/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [2500/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [2600/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [2700/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [2800/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [2900/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [3000/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3100/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3200/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [3300/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3400/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [3500/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3600/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3700/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3800/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [3900/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4000/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4100/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4200/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [4300/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4400/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4500/6250], Loss: 5.313, Acc: 0.46%\n",
            "  Batch [4600/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4700/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4800/6250], Loss: 5.313, Acc: 0.47%\n",
            "  Batch [4900/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [5000/6250], Loss: 5.314, Acc: 0.48%\n",
            "  Batch [5100/6250], Loss: 5.314, Acc: 0.48%\n",
            "  Batch [5200/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5300/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [5400/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5500/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5600/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5700/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5800/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [5900/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [6000/6250], Loss: 5.313, Acc: 0.49%\n",
            "  Batch [6100/6250], Loss: 5.313, Acc: 0.48%\n",
            "  Batch [6200/6250], Loss: 5.313, Acc: 0.48%\n",
            "Train Loss: 5.313, Train Acc: 0.48%\n",
            "Val Loss: 5.310, Val Acc: 0.50%\n",
            "\n",
            "Epoch [5/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/__init__.py\", line 2680, in <module>\n",
            "    from torch import _meta_registrations\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_meta_registrations.py\", line 12, in <module>\n",
            "    from torch._decomp import (\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_decomp/__init__.py\", line 276, in <module>\n",
            "    import torch._decomp.decompositions\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_decomp/decompositions.py\", line 16, in <module>\n",
            "    import torch._prims as prims\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_prims/__init__.py\", line 525, in <module>\n",
            "    abs = _make_elementwise_unary_prim(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_prims/__init__.py\", line 493, in _make_elementwise_unary_prim\n",
            "    return _make_prim(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_prims/__init__.py\", line 321, in _make_prim\n",
            "    prim_def = torch.library.custom_op(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_library/custom_ops.py\", line 172, in custom_op\n",
            "    return inner(fn)\n",
            "           ^^^^^^^^^\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_library/custom_ops.py\", line 153, in inner\n",
            "    result = CustomOpDef(namespace, opname, schema_str, fn, tags)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_library/custom_ops.py\", line 211, in __init__\n",
            "    self._register_to_dispatcher(self._tags)\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_library/custom_ops.py\", line 629, in _register_to_dispatcher\n",
            "    lib._register_fake(self._name, fake_impl, _stacklevel=4)\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/library.py\", line 190, in _register_fake\n",
            "    source = torch._library.utils.get_source(_stacklevel + 1)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/nicolotermine/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/_library/utils.py\", line 44, in get_source\n",
            "    frame = inspect.getframeinfo(sys._getframe(stacklevel))\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py\", line 1714, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "                  ^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py\", line 1090, in findsource\n",
            "    module = getmodule(object, file)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py\", line 1016, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "    ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen posixpath>\", line 427, in realpath\n",
            "  File \"<frozen posixpath>\", line 460, in _joinrealpath\n",
            "  File \"<frozen posixpath>\", line 82, in join\n",
            "KeyboardInterrupt\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 180\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m    183\u001b[39m val_loss, val_acc = validate(net, val_loader, criterion, device)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(net, train_loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     66\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m     67\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     70\u001b[39m     inputs, labels = inputs.to(device), labels.to(device)\n\u001b[32m     72\u001b[39m     optimizer.zero_grad()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1170\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1163\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1164\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x13e00df10>> (for post_run_cell), with arguments args (<ExecutionResult object at 1109694c0, execution_count=3 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 110f28a40, raw_cell=\"import torch\n",
            "import torch.nn as nn\n",
            "import torch.op..\" transformed_cell=\"import torch\n",
            "import torch.nn as nn\n",
            "import torch.op..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/nicolotermine/zMellow/GitHub-Poli/Polito/polito-aml/Lab_04/AML_lab04.ipynb#W3sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "[Errno 32] Broken pipe",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mBrokenPipeError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:603\u001b[39m, in \u001b[36m_WandbInit._post_run_cell_hook\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33mresuming backend\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/interface/interface.py:820\u001b[39m, in \u001b[36mInterfaceBase.publish_resume\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    819\u001b[39m     resume = pb.ResumeRequest()\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[39m, in \u001b[36mInterfaceShared._publish_resume\u001b[39m\u001b[34m(self, resume)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb.ResumeRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    333\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(resume=resume)\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[39m, in \u001b[36mInterfaceSock._publish\u001b[39m\u001b[34m(self, record, nowait)\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncer.run_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m._client.publish(request))\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_asyncer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[39m, in \u001b[36mAsyncioManager.run\u001b[39m\u001b[34m(self, fn)\u001b[39m\n\u001b[32m    133\u001b[39m future = \u001b[38;5;28mself\u001b[39m._schedule(fn, daemon=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent.futures.CancelledError:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[39m, in \u001b[36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_wrap_exceptions\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    183\u001b[39m         _logger.exception(\u001b[33m\"\u001b[39m\u001b[33mUncaught exception in run_soon callback.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/streams.py:380\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    378\u001b[39m     exc = \u001b[38;5;28mself\u001b[39m._reader.exception()\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    382\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[39m, in \u001b[36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_wrap_exceptions\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    183\u001b[39m         _logger.exception(\u001b[33m\"\u001b[39m\u001b[33mUncaught exception in run_soon callback.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/streams.py:380\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    378\u001b[39m     exc = \u001b[38;5;28mself\u001b[39m._reader.exception()\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    382\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n",
            "    \u001b[31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (3 times), StreamWriter.drain at line 380 (3 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (3 times), ServiceClient.publish at line 38 (3 times)]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[39m, in \u001b[36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_wrap_exceptions\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    183\u001b[39m         _logger.exception(\u001b[33m\"\u001b[39m\u001b[33mUncaught exception in run_soon callback.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/streams.py:380\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    378\u001b[39m     exc = \u001b[38;5;28mself\u001b[39m._reader.exception()\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    382\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[39m, in \u001b[36mAsyncioManager._wrap\u001b[39m\u001b[34m(self, fn, daemon, name)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task := asyncio.current_task()):\n\u001b[32m    217\u001b[39m         task.set_name(name)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/streams.py:380\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    378\u001b[39m     exc = \u001b[38;5;28mself\u001b[39m._reader.exception()\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    382\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[39m, in \u001b[36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_wrap_exceptions\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    183\u001b[39m         _logger.exception(\u001b[33m\"\u001b[39m\u001b[33mUncaught exception in run_soon callback.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/streams.py:380\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    378\u001b[39m     exc = \u001b[38;5;28mself\u001b[39m._reader.exception()\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    382\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[39m, in \u001b[36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_wrap_exceptions\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    183\u001b[39m         _logger.exception(\u001b[33m\"\u001b[39m\u001b[33mUncaught exception in run_soon callback.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "    \u001b[31m[... skipping similar frames: ServiceClient._send_server_request at line 64 (147 times), StreamWriter.drain at line 380 (147 times), ServiceClient.publish at line 38 (147 times), AsyncioManager.run_soon.<locals>.fn_wrap_exceptions at line 181 (146 times)]\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[39m, in \u001b[36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_wrap_exceptions\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    183\u001b[39m         _logger.exception(\u001b[33m\"\u001b[39m\u001b[33mUncaught exception in run_soon callback.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[39m, in \u001b[36mServiceClient.publish\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb.ServerRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_server_request(request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/lab-04-RLYAEv7G-py3.12/lib/python3.12/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[39m, in \u001b[36mServiceClient._send_server_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     61\u001b[39m data = request.SerializeToString()\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m._writer.write(data)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._writer.drain()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/streams.py:380\u001b[39m, in \u001b[36mStreamWriter.drain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    378\u001b[39m     exc = \u001b[38;5;28mself\u001b[39m._reader.exception()\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing():\n\u001b[32m    382\u001b[39m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py:1075\u001b[39m, in \u001b[36m_SelectorSocketTransport.write\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer:\n\u001b[32m   1073\u001b[39m     \u001b[38;5;66;03m# Optimization: try to send now.\u001b[39;00m\n\u001b[32m   1074\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m         n = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mBlockingIOError\u001b[39;00m, \u001b[38;5;167;01mInterruptedError\u001b[39;00m):\n\u001b[32m   1077\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "\u001b[31mBrokenPipeError\u001b[39m: [Errno 32] Broken pipe"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "import wandb\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Login to W&B\n",
        "wandb.login(key=\"a43845e720f3ca1353b72c93baa054db6a19fbcf\")\n",
        "\n",
        "# Define the AlexNet architecture\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=200):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Conv1: 224x224x3 -> 55x55x96\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            # Conv2: 55x55x96 -> 27x27x256\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            # Conv3: 27x27x256 -> 13x13x384\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv4: 13x13x384 -> 13x13x384\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv5: 13x13x384 -> 13x13x256\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Training function\n",
        "def train_epoch(net, train_loader, criterion, optimizer, device):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        if i % 100 == 99:\n",
        "            print(f'  Batch [{i+1}/{len(train_loader)}], Loss: {running_loss/(i+1):.3f}, Acc: {100.*correct/total:.2f}%')\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Validation function\n",
        "def validate(net, val_loader, criterion, device):\n",
        "    net.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss = running_loss / len(val_loader)\n",
        "    val_acc = 100. * correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rates = [0.1, 0.001, 0.0001]\n",
        "batch_sizes = [16, 32, 64]\n",
        "weight_decays = [5e-4, 1e-3, 1e-4]  # Different weight decay values to test\n",
        "num_epochs = 10  # Adjust based on your needs\n",
        "\n",
        "# Define transforms for the input data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the Tiny ImageNet dataset\n",
        "train_dataset = datasets.ImageFolder('../data/tiny-imagenet-200/train', transform=transform)\n",
        "val_dataset = datasets.ImageFolder('../data/tiny-imagenet-200/val', transform=transform)\n",
        "\n",
        "# Store results for final comparison\n",
        "results = []\n",
        "\n",
        "# Loop over hyperparameters\n",
        "experiment_id = 0\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for weight_decay in weight_decays:\n",
        "            experiment_id += 1\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"Experiment {experiment_id}: LR={lr}, Batch Size={batch_size}, Weight Decay={weight_decay}\")\n",
        "            print(f\"{'='*80}\\n\")\n",
        "\n",
        "            # Initialize W&B run\n",
        "            run = wandb.init(\n",
        "                project=\"alexnet-tiny-imagenet\",\n",
        "                name=f\"lr{lr}_bs{batch_size}_wd{weight_decay}\",\n",
        "                config={\n",
        "                    \"learning_rate\": lr,\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"weight_decay\": weight_decay,\n",
        "                    \"epochs\": num_epochs,\n",
        "                    \"architecture\": \"AlexNet\",\n",
        "                    \"dataset\": \"Tiny ImageNet\"\n",
        "                },\n",
        "                reinit=True\n",
        "            )\n",
        "\n",
        "            # Data loaders\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "            # Initialize the network\n",
        "            net = AlexNet(num_classes=200).to(device)\n",
        "\n",
        "            # Loss and optimizer\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "            # Learning rate scheduler (optional but recommended)\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "            # Track best validation accuracy\n",
        "            best_val_acc = 0.0\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Train the network\n",
        "            for epoch in range(num_epochs):\n",
        "                print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
        "\n",
        "                # Training\n",
        "                train_loss, train_acc = train_epoch(net, train_loader, criterion, optimizer, device)\n",
        "\n",
        "                # Validation\n",
        "                val_loss, val_acc = validate(net, val_loader, criterion, device)\n",
        "\n",
        "                # Update learning rate\n",
        "                scheduler.step()\n",
        "\n",
        "                # Log metrics to W&B\n",
        "                wandb.log({\n",
        "                    \"epoch\": epoch + 1,\n",
        "                    \"train_loss\": train_loss,\n",
        "                    \"train_acc\": train_acc,\n",
        "                    \"val_loss\": val_loss,\n",
        "                    \"val_acc\": val_acc,\n",
        "                    \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "                })\n",
        "\n",
        "                print(f\"Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%\")\n",
        "                print(f\"Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "                # Save best model\n",
        "                if val_acc > best_val_acc:\n",
        "                    best_val_acc = val_acc\n",
        "                    torch.save(net.state_dict(), f'best_alexnet_lr{lr}_bs{batch_size}_wd{weight_decay}.pth')\n",
        "\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            # Final evaluation\n",
        "            final_val_loss, final_val_acc = validate(net, val_loader, criterion, device)\n",
        "\n",
        "            # Store results\n",
        "            results.append({\n",
        "                'Learning Rate': lr,\n",
        "                'Batch Size': batch_size,\n",
        "                'Weight Decay': weight_decay,\n",
        "                'Best Val Acc': f\"{best_val_acc:.2f}%\",\n",
        "                'Final Val Acc': f\"{final_val_acc:.2f}%\",\n",
        "                'Training Time (min)': f\"{training_time/60:.2f}\"\n",
        "            })\n",
        "\n",
        "            # Log final metrics to W&B\n",
        "            wandb.log({\n",
        "                \"best_val_acc\": best_val_acc,\n",
        "                \"final_val_acc\": final_val_acc,\n",
        "                \"training_time_minutes\": training_time/60\n",
        "            })\n",
        "\n",
        "            print(f\"\\nExperiment completed in {training_time/60:.2f} minutes\")\n",
        "            print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "            # Finish W&B run\n",
        "            wandb.finish()\n",
        "\n",
        "# Print final comparison table\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"FINAL RESULTS COMPARISON\")\n",
        "print(\"=\"*100 + \"\\n\")\n",
        "\n",
        "# Create table\n",
        "headers = results[0].keys()\n",
        "rows = [list(r.values()) for r in results]\n",
        "print(tabulate(rows, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "# Find best configuration\n",
        "best_result = max(results, key=lambda x: float(x['Best Val Acc'].rstrip('%')))\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"BEST CONFIGURATION:\")\n",
        "print(\"=\"*100)\n",
        "print(f\"Learning Rate: {best_result['Learning Rate']}\")\n",
        "print(f\"Batch Size: {best_result['Batch Size']}\")\n",
        "print(f\"Weight Decay: {best_result['Weight Decay']}\")\n",
        "print(f\"Best Validation Accuracy: {best_result['Best Val Acc']}\")\n",
        "print(f\"Training Time: {best_result['Training Time (min)']} minutes\")\n",
        "print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCFg8gufD9d5"
      },
      "source": [
        "Tre artifact\n",
        "\n",
        "## 1. **ResNet Training** (primo artifact)\n",
        "Codice equivalente a quello di AlexNet ma con l'architettura ResNet18, che include:\n",
        "- Implementazione completa di ResNet con blocchi residuali\n",
        "- Stessa configurazione di hyperparameter tuning\n",
        "- Integrazione W&B per tracking\n",
        "- Salvataggio dei risultati in `resnet18_results.pkl`\n",
        "\n",
        "## 2. **Confronto Tabellare** (secondo artifact)\n",
        "Script che carica i risultati di entrambe le architetture e produce:\n",
        "- **Tabelle complete** di tutti gli esperimenti\n",
        "- **Statistiche aggregate** (media, max, min, std)\n",
        "- **Top 5 configurazioni** per ogni architettura\n",
        "- **Confronto head-to-head** delle migliori configurazioni\n",
        "- **Analisi per iperparametro** (effetto di LR, BS, WD)\n",
        "- **Key findings** con conclusioni automatiche\n",
        "\n",
        "## 3. **Visualizzazioni Grafiche** (terzo artifact)\n",
        "Script che genera 9 grafici in 2 immagini PNG:\n",
        "\n",
        "**architecture_comparison.png** contiene:\n",
        "1. Box plot distribuzione accuracy\n",
        "2. Scatter plot accuracy vs training time\n",
        "3. Bar chart effetto learning rate\n",
        "4. Bar chart effetto batch size\n",
        "5. Bar chart effetto weight decay\n",
        "6. Heatmap differenza di performance\n",
        "\n",
        "**detailed_analysis.png** contiene:\n",
        "7. Top 10 configurazioni a confronto\n",
        "8. Istogramma distribuzione tempi di training\n",
        "9. Error bar per robustezza delle configurazioni\n",
        "\n",
        "### Come usare:\n",
        "1. Esegui prima il training di AlexNet (già fornito)\n",
        "2. Esegui il training di ResNet18 (primo nuovo artifact)\n",
        "3. Esegui l'analisi tabellare (secondo artifact)\n",
        "4. Esegui la visualizzazione grafica (terzo artifact)\n",
        "\n",
        "Tutti i risultati verranno salvati e visualizzati sia su W&B che localmente!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2WlO0fYD352"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import time\n",
        "import wandb\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Login to W&B\n",
        "wandb.login(key=\"a43845e720f3ca1353b72c93baa054db6a19fbcf\")\n",
        "\n",
        "# Define the ResNet architecture with residual blocks\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=200):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        # Initial convolution layer\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Residual layers\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def ResNet18(num_classes=200):\n",
        "    return ResNet(ResidualBlock, [2, 2, 2, 2], num_classes)\n",
        "\n",
        "def ResNet34(num_classes=200):\n",
        "    return ResNet(ResidualBlock, [3, 4, 6, 3], num_classes)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(net, train_loader, criterion, optimizer, device):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        if i % 100 == 99:\n",
        "            print(f'  Batch [{i+1}/{len(train_loader)}], Loss: {running_loss/(i+1):.3f}, Acc: {100.*correct/total:.2f}%')\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Validation function\n",
        "def validate(net, val_loader, criterion, device):\n",
        "    net.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss = running_loss / len(val_loader)\n",
        "    val_acc = 100. * correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rates = [0.1, 0.001, 0.0001]\n",
        "batch_sizes = [16, 32, 64]\n",
        "weight_decays = [5e-4, 1e-3, 1e-4]\n",
        "num_epochs = 10\n",
        "\n",
        "# Define transforms for the input data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the Tiny ImageNet dataset\n",
        "train_dataset = datasets.ImageFolder('../data/tiny-imagenet-200/train', transform=transform)\n",
        "val_dataset = datasets.ImageFolder('../data/tiny-imagenet-200/val', transform=transform)\n",
        "\n",
        "# Store results for final comparison\n",
        "results = []\n",
        "\n",
        "# Loop over hyperparameters\n",
        "experiment_id = 0\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for weight_decay in weight_decays:\n",
        "            experiment_id += 1\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(f\"Experiment {experiment_id}: LR={lr}, Batch Size={batch_size}, Weight Decay={weight_decay}\")\n",
        "            print(f\"{'='*80}\\n\")\n",
        "\n",
        "            # Initialize W&B run\n",
        "            run = wandb.init(\n",
        "                project=\"resnet-tiny-imagenet\",\n",
        "                name=f\"resnet18_lr{lr}_bs{batch_size}_wd{weight_decay}\",\n",
        "                config={\n",
        "                    \"learning_rate\": lr,\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"weight_decay\": weight_decay,\n",
        "                    \"epochs\": num_epochs,\n",
        "                    \"architecture\": \"ResNet18\",\n",
        "                    \"dataset\": \"Tiny ImageNet\"\n",
        "                },\n",
        "                reinit=True\n",
        "            )\n",
        "\n",
        "            # Data loaders\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "            # Initialize the network (using ResNet18)\n",
        "            net = ResNet18(num_classes=200).to(device)\n",
        "\n",
        "            # Loss and optimizer\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "            # Learning rate scheduler\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "            # Track best validation accuracy\n",
        "            best_val_acc = 0.0\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Train the network\n",
        "            for epoch in range(num_epochs):\n",
        "                print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
        "\n",
        "                # Training\n",
        "                train_loss, train_acc = train_epoch(net, train_loader, criterion, optimizer, device)\n",
        "\n",
        "                # Validation\n",
        "                val_loss, val_acc = validate(net, val_loader, criterion, device)\n",
        "\n",
        "                # Update learning rate\n",
        "                scheduler.step()\n",
        "\n",
        "                # Log metrics to W&B\n",
        "                wandb.log({\n",
        "                    \"epoch\": epoch + 1,\n",
        "                    \"train_loss\": train_loss,\n",
        "                    \"train_acc\": train_acc,\n",
        "                    \"val_loss\": val_loss,\n",
        "                    \"val_acc\": val_acc,\n",
        "                    \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "                })\n",
        "\n",
        "                print(f\"Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%\")\n",
        "                print(f\"Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "                # Save best model\n",
        "                if val_acc > best_val_acc:\n",
        "                    best_val_acc = val_acc\n",
        "                    torch.save(net.state_dict(), f'best_resnet18_lr{lr}_bs{batch_size}_wd{weight_decay}.pth')\n",
        "\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            # Final evaluation\n",
        "            final_val_loss, final_val_acc = validate(net, val_loader, criterion, device)\n",
        "\n",
        "            # Store results\n",
        "            results.append({\n",
        "                'Architecture': 'ResNet18',\n",
        "                'Learning Rate': lr,\n",
        "                'Batch Size': batch_size,\n",
        "                'Weight Decay': weight_decay,\n",
        "                'Best Val Acc': f\"{best_val_acc:.2f}%\",\n",
        "                'Final Val Acc': f\"{final_val_acc:.2f}%\",\n",
        "                'Training Time (min)': f\"{training_time/60:.2f}\"\n",
        "            })\n",
        "\n",
        "            # Log final metrics to W&B\n",
        "            wandb.log({\n",
        "                \"best_val_acc\": best_val_acc,\n",
        "                \"final_val_acc\": final_val_acc,\n",
        "                \"training_time_minutes\": training_time/60\n",
        "            })\n",
        "\n",
        "            print(f\"\\nExperiment completed in {training_time/60:.2f} minutes\")\n",
        "            print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "            # Finish W&B run\n",
        "            wandb.finish()\n",
        "\n",
        "# Print final comparison table\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"FINAL RESULTS COMPARISON - RESNET18\")\n",
        "print(\"=\"*100 + \"\\n\")\n",
        "\n",
        "# Create table\n",
        "headers = results[0].keys()\n",
        "rows = [list(r.values()) for r in results]\n",
        "print(tabulate(rows, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "# Find best configuration\n",
        "best_result = max(results, key=lambda x: float(x['Best Val Acc'].rstrip('%')))\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"BEST CONFIGURATION:\")\n",
        "print(\"=\"*100)\n",
        "print(f\"Architecture: {best_result['Architecture']}\")\n",
        "print(f\"Learning Rate: {best_result['Learning Rate']}\")\n",
        "print(f\"Batch Size: {best_result['Batch Size']}\")\n",
        "print(f\"Weight Decay: {best_result['Weight Decay']}\")\n",
        "print(f\"Best Validation Accuracy: {best_result['Best Val Acc']}\")\n",
        "print(f\"Training Time: {best_result['Training Time (min)']} minutes\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "# Save results to file for later comparison\n",
        "import pickle\n",
        "with open('resnet18_results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "print(\"\\nResults saved to 'resnet18_results.pkl'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lab-04-RLYAEv7G-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
